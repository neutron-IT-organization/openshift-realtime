{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Utiliser les capacit\u00e9s temps r\u00e9el d'OpenShift","text":"<p>Face \u00e0 l'essor des applications \u00e0 contraintes temps r\u00e9el dans les environnements industriels et financiers, les entreprises doivent repenser leurs infrastructures pour offrir \u00e0 la fois flexibilit\u00e9, faible latence et robustesse. OpenShift, la plateforme de Red Hat bas\u00e9e sur Kubernetes, propose des capacit\u00e9s temps r\u00e9el pour des workloads containers et machines virtuelles, tout en garantissant la s\u00e9curit\u00e9 de ceux-ci.  Cet article explore comment configurer une infrastructure mixte - containers et VMs - optimis\u00e9e pour les contraintes temps r\u00e9el.</p>"},{"location":"#contexte-et-enjeux-des-contraintes-temps-reel-sur-openshift","title":"Contexte et enjeux des contraintes temps r\u00e9el sur OpenShift","text":""},{"location":"#les-defis-des-workloads-temps-reel","title":"Les d\u00e9fis des workloads temps r\u00e9el","text":"<p>Les applications temps r\u00e9el exigent un traitement des donn\u00e9es et une r\u00e9ponse aux \u00e9v\u00e9nements dans des d\u00e9lais extr\u00eamement courts et stables. Parmi les enjeux principaux, on retrouve : - La pr\u00e9visibilit\u00e9 du temps de r\u00e9ponse : L'isolation des ressources (CPU, m\u00e9moire et E/S) est indispensable pour \u00e9viter les interf\u00e9rences. - La latence r\u00e9seau minimale : Pour les communications critiques, il est souvent n\u00e9cessaire d'utiliser des interfaces r\u00e9seau qui contournent les couches de virtualisation classiques. - La gestion simultan\u00e9e de containers et de VMs : Certains workloads h\u00e9rit\u00e9s fonctionnant en VM doivent cohabiter avec des applications nativement containeris\u00e9es, sans compromettre la performance globale.  </p>"},{"location":"#openshift-comme-plateforme-unifiee","title":"OpenShift comme plateforme unifi\u00e9e","text":"<p>OpenShift permet de r\u00e9unir ces deux types de workloads \u00e0 l'aide de son op\u00e9rateur OpenShift Virtualization. Ainsi, il devient possible de g\u00e9rer dans une m\u00eame plateforme des applications containeris\u00e9es ultra r\u00e9actives et des VMs pour des charges traditionnelles. Cette approche facilite notamment la migration progressive des applications vers des architectures modernes tout en garantissant un temps de r\u00e9ponse optimal.</p>"},{"location":"#integration-de-containers-et-vms-pour-des-workloads-temps-reel","title":"Int\u00e9gration de containers et VMs pour des workloads temps r\u00e9el","text":""},{"location":"#configuration-dopenshift","title":"Configuration d'OpenShift","text":"<p>Pour ex\u00e9cuter des workloads temps r\u00e9el, OpenShift doit \u00eatre configur\u00e9 avec : - Un noyau temps r\u00e9el : Disponible via l'op\u00e9rateur OpenShift RT, ce noyau permet d'am\u00e9liorer la stabilit\u00e9 des temps de r\u00e9ponse. - L'isolation des CPUs : En d\u00e9diant des c\u0153urs sp\u00e9cifiques aux t\u00e2ches critiques, on r\u00e9duit la variabilit\u00e9 des performances. - L'optimisation des interruptions : Ajuster les IRQs et configurer l'affinit\u00e9 CPU permet d'\u00e9viter les interruptions non d\u00e9sir\u00e9es. - L'utilisation de HugePages : Cela optimise l'utilisation m\u00e9moire et am\u00e9liore la gestion des latences.  Tout ceci peut \u00eatre configur\u00e9 \u00e0 l'aide d'un <code>PerformanceProfile</code>.</p> <p></p>"},{"location":"#configuration-dun-performanceprofile","title":"Configuration d'un PerformanceProfile","text":"<p>L'activation des performances temps r\u00e9el passe par la cr\u00e9ation d'un <code>PerformanceProfile</code> d\u00e9di\u00e9 :</p> <pre><code>---\napiVersion: performance.openshift.io/v2\nkind: PerformanceProfile\nmetadata:\n  name: rt-profile\nspec:\n  cpu:\n    isolated: 2-7\n    reserved: 0-1\n  hugepages:\n    defaultHugepagesSize: 1G\n    pages:\n      - count: 4\n        size: 1G\n  realTimeKernel:\n    enabled: true\n  workloadHints:\n    realTime: true\n  nodeSelector:\n    node-role.kubernetes.io/worker-rt: \"\"\n</code></pre>"},{"location":"#deploiement-dun-container-temps-reel","title":"D\u00e9ploiement d'un container temps r\u00e9el","text":"<p>Pour d\u00e9ployer un container temps r\u00e9el sur OpenShift en QoS guaranteed :</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: rt-container\nspec:\n  containers:\n  - name: app-rt\n    image: registry.example.com/rt-app:latest\n    resources:\n      requests:\n        cpu: \"2\"\n        memory: \"2Gi\"\n        hugepages-1Gi: \"2Gi\"\n      limits:\n        cpu: \"2\"\n        memory: \"2Gi\"\n        hugepages-1Gi: \"2Gi\"\n    securityContext:\n      capabilities:\n        add:\n        - SYS_NICE # Allows the container to adjust scheduling priorities.\n        - IPC_LOCK # Enables locking memory to prevent swapping (used in real-time applications).\n</code></pre>"},{"location":"#explication-des-qos-dans-openshift","title":"Explication des QoS dans OpenShift","text":"<p><code>guaranteed</code>: Cette classe garantit l'allocation des ressources, elle est d\u00e9finie lorsqu'on sp\u00e9cifie <code>requests</code>\u00e9gal \u00e0 <code>limits</code>.</p> <p><code>burstable</code> : Cette classe permet d'allouer plus de ressources si celles-ci sont disponibles, elle est d\u00e9finie lorsqu'on sp\u00e9cifie <code>limits</code> sup\u00e9rieur \u00e0 <code>requests</code>.</p> <p><code>bestEffort</code> : Cette classe utilise les ressources disponibles dynamiquement et peut \u00eatre expuls\u00e9 si le n\u0153ud manque de ressources, elle est d\u00e9finie lorsqu'on ne sp\u00e9cifie aucune <code>requests</code> et aucune <code>limits</code>.</p>"},{"location":"#deploiement-dune-vm-temps-reel","title":"D\u00e9ploiement d'une VM temps r\u00e9el","text":"<p>Pour cr\u00e9er une VM temps r\u00e9el avec OpenShift Virtualization :</p> <pre><code>apiVersion: kubevirt.io/v1\nkind: VirtualMachine\nmetadata:\n  name: rt-vm\nspec:\n  running: true\n  template:\n    spec:\n      domain:\n        cpu:\n          model: \"host-passthrough\" # Uses the host CPU model for optimal performance.\n          cores: 2 # Number of virtual CPU cores allocated to the VM.\n          dedicatedCpuPlacement: true # Ensures CPU cores are dedicated for the VM.\n          isolateEmulatorThread: true # Isolates the emulator thread for better latency.\n        memory:\n          hugepages:\n            pageSize: \"1Gi\"\n        resources:\n          requests:\n            memory: \"4Gi\"\n          limits:\n            memory: \"4Gi\"\n        devices:\n          disks:\n            - name: rootdisk\n              disk:\n                bus: virtio\n          interfaces:\n            - name: default\n              bridge: {}\n      networks:\n        - name: default\n          pod: {}\n  dataVolumeTemplates:\n    - metadata:\n        name: rt-vm-disk\n      spec:\n        source:\n          http:\n            url: \"http://example.com/rt-vm.qcow2\"\n        pvc:\n          accessModes:\n            - ReadWriteOnce\n          resources:\n            requests:\n              storage: 10Gi\n</code></pre>"},{"location":"#explication-des-parametres-cles-des-vms-temps-reel","title":"Explication des param\u00e8tres cl\u00e9s des VMs temps r\u00e9el","text":"<p><code>host-passthrough</code> : Ce param\u00e8tre permet de passer directement le mod\u00e8le de CPU de l'h\u00f4te \u00e0 la VM, garantissant ainsi une compatibilit\u00e9 et une performance maximales. Il \u00e9vite l'\u00e9mulation de certaines instructions CPU, r\u00e9duisant ainsi la latence et augmentant la stabilit\u00e9 du temps de r\u00e9ponse.</p> <p><code>dedicatedCpuPlacement</code> : L'activation de cette option garantit que les c\u0153urs CPU allou\u00e9s \u00e0 la VM ne seront pas partag\u00e9s avec d'autres workloads, am\u00e9liorant ainsi la pr\u00e9visibilit\u00e9 des performances et minimisant l'interf\u00e9rence avec d'autres processus ex\u00e9cut\u00e9s sur le n\u0153ud.</p> <p><code>isolateEmulatorThread</code> : L'activation de ce param\u00e8tre permet d'isoler le thread de l'\u00e9mulateur, ce qui r\u00e9duit la latence de l'\u00e9mulation et am\u00e9liore les performances en cas de workloads n\u00e9cessitant un traitement rapide et d\u00e9terministe.</p>"},{"location":"#utilisation-dune-interface-reseau-l2","title":"Utilisation d'une interface r\u00e9seau L2","text":"<p>Les applications temps r\u00e9el requi\u00e8rent souvent une communication r\u00e9seau \u00e0 faible latence et haut d\u00e9bit. L'utilisation d'une interface r\u00e9seau L2 permet de r\u00e9duire la surcharge introduite par les couches de virtualisation r\u00e9seau classiques et d'offrir une connectivit\u00e9 directe entre les workloads.   </p> <p>OpenShift permet d'exploiter Multus pour cr\u00e9er des interfaces L2 en utilisant macvlan. </p>"},{"location":"#creation-dun-nad-multus-en-macvlan","title":"Cr\u00e9ation d'un NAD Multus en macvlan","text":"<pre><code>apiVersion: k8s.cni.cncf.io/v1\nkind: NetworkAttachmentDefinition\nmetadata:\n  name: l2-interface\n  namespace: example-namespace\nspec:\n  config: '{\n    \"cniVersion\": \"0.3.1\",\n    \"type\": \"macvlan\",\n    \"master\": \"enp3s0\",\n    \"mode\": \"bridge\",\n    \"ipam\": { \"type\": \"dhcp\" }\n  }'\n</code></pre>"},{"location":"#association-dune-interface-l2-a-un-container","title":"Association d'une interface L2 \u00e0 un container","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: rt-container-l2\n  annotations:\n    k8s.v1.cni.cncf.io/networks: example-namespace/l2-interface\nspec:\n  containers:\n  - name: rt-app\n    image: registry.example.com/rt-app:latest\n</code></pre>"},{"location":"#association-dune-interface-l2-a-une-vm","title":"Association d'une interface L2 \u00e0 une VM","text":"<pre><code>spec:\n  template:\n    spec:\n      networks:\n        - name: l2-net\n          multus:\n            networkName: example-namespace/l2-interface\n      domain:\n        devices:\n          interfaces:\n            - name: l2-net\n              bridge: {}\n</code></pre>"},{"location":"#conclusion","title":"Conclusion","text":"<p>OpenShift offre une plateforme unifi\u00e9e pour ex\u00e9cuter des workloads temps r\u00e9el en combinant containers et machines virtuelles. Gr\u00e2ce \u00e0 ses capacit\u00e9s d'optimisation des performances, de gestion fine des ressources et de mise en r\u00e9seau avanc\u00e9e, il r\u00e9pond aux exigences des environnements industriels et financiers critiques. En configurant correctement les ressources CPU, m\u00e9moire et r\u00e9seau, il est possible d'atteindre une faible latence et une grande pr\u00e9visibilit\u00e9, garantissant ainsi la stabilit\u00e9 et la performance des applications temps r\u00e9el.</p>"}]}